{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78763e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b7abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['dst_host_same_src_port_rate',\n",
    " 'is_guest_login',\n",
    " 'num_failed_logins',\n",
    " 'dst_host_diff_srv_rate',\n",
    " 'rerror_rate',\n",
    " 'logged_in',\n",
    " 'serror_rate',\n",
    " 'same_srv_rate',\n",
    " 'protocol_type_0',\n",
    "'protocol_type_1', \n",
    " 'dst_host_srv_diff_host_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53406654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../../transformed_datasets/transformed_KDD_CUPP99_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a094a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "for feature in df.columns:\n",
    "    if df[feature].dtype == 'int64' or df[feature].dtype == 'float64':\n",
    "        feature_columns.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7238de2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_be_normalised = []\n",
    "for feature in feature_columns:\n",
    "    if not df[feature].min() >= 0.0 and df[feature].max() <= 1.0:\n",
    "        features_to_be_normalised.append(feature)\n",
    "df['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf49161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# df[features_to_be_normalised] = scaler.fit_transform(df[features_to_be_normalised])\n",
    "# df.describe()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b659c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({col: 'float32' for col in df.select_dtypes(include=['int', 'float64']).columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc4f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "for f in selected_features:\n",
    "    print(df[f].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9812b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tensor = torch.tensor(df[selected_features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f71938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tensor = torch.tensor(df['label'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59c100f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e370dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(features_tensor, target_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c36040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e47b3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(11, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 38),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c15d6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLayerPerceptron().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4087ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5b8373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloader, loss_fn, model, optimizer):\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)  # Move data to the device\n",
    "        prediction = model(X)\n",
    "        loss = loss_fn(prediction, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "513e53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)  # Move data to the device\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fa9f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e287a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5282b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.038312 \n",
      "\n",
      "1\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.037904 \n",
      "\n",
      "2\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.037512 \n",
      "\n",
      "3\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.037150 \n",
      "\n",
      "4\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.036788 \n",
      "\n",
      "5\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.036469 \n",
      "\n",
      "6\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.036128 \n",
      "\n",
      "7\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.035831 \n",
      "\n",
      "8\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.035537 \n",
      "\n",
      "9\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.035268 \n",
      "\n",
      "10\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.035051 \n",
      "\n",
      "11\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.034742 \n",
      "\n",
      "12\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.034518 \n",
      "\n",
      "13\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.034288 \n",
      "\n",
      "14\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.034085 \n",
      "\n",
      "15\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.033875 \n",
      "\n",
      "16\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.033681 \n",
      "\n",
      "17\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.033498 \n",
      "\n",
      "18\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.033300 \n",
      "\n",
      "19\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.033250 \n",
      "\n",
      "20\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.033044 \n",
      "\n",
      "21\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.032823 \n",
      "\n",
      "22\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.032665 \n",
      "\n",
      "23\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.032519 \n",
      "\n",
      "24\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.032397 \n",
      "\n",
      "25\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.032295 \n",
      "\n",
      "26\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.032175 \n",
      "\n",
      "27\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.032006 \n",
      "\n",
      "28\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.031989 \n",
      "\n",
      "29\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.031861 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print(i)\n",
    "    train_model(dataloader, loss_fn, model, optimizer)\n",
    "    test_model(dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc23bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c3bef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2755.8562529087067"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c75b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
